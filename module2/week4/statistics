### Question 1
import numpy as np

def compute_mean(X):
    mean = np.mean(X)
    return mean

X = [2 , 0 , 2 , 2 , 7, 4 , -2 , 5 , -1 , -1]
print (" Mean:", compute_mean(X))
### Question 2

def compute_median(X):
    size = len(X)
    X = np.sort(X)
    print(X)
    if (size % 2 == 0) :
        return X[int(size/2 - 1)]
    else :
        return X[round(size/2, 0)]

X = [1 , 5 , 4 , 4 , 9, 13]
print ("Median:", compute_median(X))
### Question 3

def compute_std(X):

    mean = compute_mean(X)
    variance = np.var(X)
    return np.sqrt(variance)

X = [171, 176, 155, 167, 169, 182]

print(compute_std(X))
### Question 4

def compute_correlation_cofficient(X, Y):
    N = len(X)
    numerator = N*np.dot(X, Y) - np.sum(X)*np.sum(Y)
    denominator = np.sqrt((N*np.sum(X**2) - (np.sum(X))**2)) * np.sqrt((N*np.sum(Y**2) - (np.sum(Y))**2))

    return np.round(numerator/denominator, 2)

X = np.asarray([-2, -5, -11, 6, 4, 15, 9])
Y = np.asarray([4, 25, 121, 36, 16, 225, 81])
print ("Correlation:", compute_correlation_cofficient (X, Y))
### Question 5
# Download dataset:
!gdown 1iA0WmVfW88HyJvTBSQDI5vesf-pgKabq

import pandas as pd
data = pd.read_csv('advertising.csv')

def correlation(x, y):

    mean_x = np.mean(x)
    mean_y = np.mean(y)

    numerator = np.sum(np.dot((x - mean_x), (y - mean_y)))
    denominator = np.sqrt(np.sum((x - mean_x)**2)) * np.sqrt(np.sum((y - mean_y)**2))
    
    return round(numerator / denominator, 2)

# Example usage :
x = data['TV']
y = data['Radio']
corr_xy = correlation(x, y)
print(f"Correlation between TV and Sales: {round(corr_xy, 2)}")
### Question 6
data = pd.read_csv('advertising.csv')

def correlation(x, y):
    mean_x = np.mean(x)
    mean_y = np.mean(y)

    numerator = np.sum(np.dot((x - mean_x), (y - mean_y)))
    denominator = np.sqrt(np.sum((x - mean_x)**2)) * np.sqrt(np.sum((y - mean_y)**2))
    
    return round(numerator / denominator, 2)

features = ['TV', 'Radio', 'Newspaper']

for feature_1 in features:
    for feature_2 in features:
        correlation_value = correlation(data[feature_1], data[feature_2])
        print(f"Correlation between {feature_1} and {feature_2}: {round(correlation_value, 2)}")
### Question 10
# Download dataset : 
!gdown 1jh2p2DlaWsDo_vEWIcTrNh3mUuXd-cw6

import pandas as pd
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import TfidfVectorizer

vi_data_df = pd.read_csv('./vi_text_retrieval.csv')
context = vi_data_df['text']
context = [doc.lower() for doc in context]

tfidf_vectorizer = TfidfVectorizer()
context_embedded = tfidf_vectorizer.fit_transform(context)
context_embedded.toarray()[7][0]
### Question 11
def tfidf_search(question, tfidf_vectorizer, top_d = 5):
    # Lowercasing before encoding
    query_embedded = tfidf_vectorizer.transform([question.lower()])
    # Calculating cosine similarity scores
    tfidf_matrix = tfidf_vectorizer.fit_transform(context)
    cosine_scores = cosine_similarity(query_embedded, tfidf_matrix).flatten()

    # Get top k cosine score and index its
    results = []
    for idx in cosine_scores.argsort()[-top_d:][::-1]:
        doc_score = {
            'id': idx,
            'cosine_score': cosine_scores[idx]
        }
        results.append(doc_score)
    return results

question = vi_data_df.iloc[0]['question']
results = tfidf_search(question, tfidf_vectorizer, top_d = 5)
results[0]['cosine_score']
### Question 12
def corr_search(question, tfidf_vectorizer, top_d =5) :
    # lowercasing before encoding
    query_embedded = tfidf_vectorizer.transform([question.lower()])
    tfidf_matrix = tfidf_vectorizer.fit_transform(context)
    # Calculating cosine similarity scores (used here as correlation scores)
    corr_scores = cosine_similarity(query_embedded, tfidf_matrix)
    # Flatten the result to get a 1D array and remove the self-correlation score
    corr_scores = corr_scores.flatten()

    # Get top k correlation score and index its
    results = []
    for idx in corr_scores.argsort()[-top_d:][::-1]:
        doc = {
            'id': idx,
            'corr_score': corr_scores[idx]
        }
        results.append(doc)
    return results

question = vi_data_df.iloc[0]['question']
results = corr_search(question, tfidf_vectorizer, top_d =5)
results[1]['corr_score']
